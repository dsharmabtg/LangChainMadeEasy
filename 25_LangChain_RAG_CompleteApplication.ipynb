{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbe67fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "632c8dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_contents(filename):\n",
    "    \"\"\" Given a filename,\n",
    "        return the contents of that file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(filename, 'r') as f:\n",
    "            # It's assumed our file contains a single line,\n",
    "            # with our API key\n",
    "            return f.read().strip()\n",
    "    except FileNotFoundError:\n",
    "        print(\"'%s' file not found\" % filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e02e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"..\\\\GoogleAPIKey.txt\"\n",
    "os.environ['GOOGLE_API_KEY'] = get_file_contents(filename)\n",
    "filename_grokKey = \"..\\\\GroqAPIKey.txt\"\n",
    "os.environ['GROQ_API_KEY'] = get_file_contents(filename_grokKey)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1779d915",
   "metadata": {},
   "source": [
    "### Retrievers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3aa7fdb",
   "metadata": {},
   "source": [
    "#### vector store base retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39e8a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed069bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_model = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad132218",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 376, which is longer than the specified 300\n",
      "Created a chunk of size 412, which is longer than the specified 300\n",
      "Created a chunk of size 497, which is longer than the specified 300\n",
      "Created a chunk of size 426, which is longer than the specified 300\n",
      "Created a chunk of size 389, which is longer than the specified 300\n",
      "Created a chunk of size 760, which is longer than the specified 300\n"
     ]
    }
   ],
   "source": [
    "#Load the documents and split it into chunks, embed each chunk  and load it into vector store\n",
    "raw_documents = TextLoader(\"..\\\\RAGFiles\\\\LangchainRetrieval.txt\").load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=300,chunk_overlap=20)\n",
    "documents = text_splitter.split_documents(raw_documents)\n",
    "db =  Chroma.from_documents(documents,embeddings_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "802cf1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "retreivers = db.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c9fa64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"What is text embedding and how does langchain help in doing it\"\n",
    "docs = retreivers.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43f27aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='97faa254-46a5-40c8-94b3-384f4a6a7843', metadata={'source': '..\\\\RAGFiles\\\\LangchainRetrieval.txt'}, page_content='Text embedding models\\nAnother key part of retrieval is creating embeddings for documents. Embeddings capture the semantic meaning of the text, allowing you to quickly and efficiently find other pieces of a text that are similar. LangChain provides integrations with over 25 different embedding providers and methods, from open-source to proprietary API, allowing you to choose the one best suited for your needs. LangChain provides a standard interface, allowing you to easily swap between models.'),\n",
       " Document(id='5e6c177d-5f80-42f3-8884-ea19882391be', metadata={'source': '..\\\\RAGFiles\\\\LangchainRetrieval.txt'}, page_content='Text embedding models\\nAnother key part of retrieval is creating embeddings for documents. Embeddings capture the semantic meaning of the text, allowing you to quickly and efficiently find other pieces of a text that are similar. LangChain provides integrations with over 25 different embedding providers and methods, from open-source to proprietary API, allowing you to choose the one best suited for your needs. LangChain provides a standard interface, allowing you to easily swap between models.'),\n",
       " Document(id='7369ab79-d8b4-49c9-8470-532b0bc20f01', metadata={'source': '..\\\\RAGFiles\\\\LangchainRetrieval.txt'}, page_content='Text embedding models\\nAnother key part of retrieval is creating embeddings for documents. Embeddings capture the semantic meaning of the text, allowing you to quickly and efficiently find other pieces of a text that are similar. LangChain provides integrations with over 25 different embedding providers and methods, from open-source to proprietary API, allowing you to choose the one best suited for your needs. LangChain provides a standard interface, allowing you to easily swap between models.\\n\\nVector stores\\nWith the rise of embeddings, there has emerged a need for databases to support efficient storage and searching of these embeddings. LangChain provides integrations with over 50 different vectorstores, from open-source local ones to cloud-hosted proprietary ones, allowing you to choose the one best suited for your needs. LangChain exposes a standard interface, allowing you to easily swap between vector stores.'),\n",
       " Document(id='e1db27a9-ab92-449e-b1f5-d9a6d8868f14', metadata={'source': '..\\\\RAGFiles\\\\LangchainRetrieval.txt'}, page_content=\"Parent Document Retriever: This allows you to create multiple embeddings per parent document, allowing you to look up smaller chunks but return larger context.\\nSelf Query Retriever: User questions often contain a reference to something that isn't just semantic but rather expresses some logic that can best be represented as a metadata filter. Self-query allows you to parse out the semantic part of a query from other metadata filters present in the query.\\nEnsemble Retriever: Sometimes you may want to retrieve documents from multiple different sources, or using multiple different algorithms. The ensemble retriever allows you to easily do this.\\nAnd more!\\nIndexing\\nThe LangChain Indexing API syncs your data from any source into a vector store, helping you:\")]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dc26ba52",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "    Answer the question based only on the following context:\n",
    "    {context}\n",
    "    Question:{question}\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template)\n",
    "model= ChatGoogleGenerativeAI(model='gemini-1.5-pro-001')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "298f7f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join([d.page_content for d in docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fcfc75fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {\"context\":retreivers|format_docs, \"question\":RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3ec1c1b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text embedding is the process of capturing the semantic meaning of text and representing it as a vector (a list of numbers). This allows for quick and efficient searching for similar pieces of text. \n",
      "\n",
      "LangChain assists in this process by providing:\n",
      "\n",
      "* **Integrations:**  It connects with over 25 different embedding providers, both open-source and proprietary, giving users flexibility and choice.\n",
      "* **Standard Interface:**  This makes it easy to switch between different embedding models without needing to rewrite large portions of code. \n"
     ]
    }
   ],
   "source": [
    "print(chain.invoke(\"What is text embedding and how does langchain help in doing it\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51cc573c",
   "metadata": {},
   "source": [
    "#### Number of relevant similar documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "98341a97",
   "metadata": {},
   "outputs": [],
   "source": [
    "retreivers = db.as_retriever(search_kwargs={\"k\":1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a82ef6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"What is text embedding and how does langchain help in doing it\"\n",
    "docs = retreivers.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2bba3e32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='5e6c177d-5f80-42f3-8884-ea19882391be', metadata={'source': '..\\\\RAGFiles\\\\LangchainRetrieval.txt'}, page_content='Text embedding models\\nAnother key part of retrieval is creating embeddings for documents. Embeddings capture the semantic meaning of the text, allowing you to quickly and efficiently find other pieces of a text that are similar. LangChain provides integrations with over 25 different embedding providers and methods, from open-source to proprietary API, allowing you to choose the one best suited for your needs. LangChain provides a standard interface, allowing you to easily swap between models.')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375ed0db",
   "metadata": {},
   "source": [
    "#### Score Threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "81f93596",
   "metadata": {},
   "outputs": [],
   "source": [
    "retreivers = db.as_retriever(search_type=\"similarity_score_threshold\",search_kwargs={\"score_threshold\":0.70}) \n",
    "#0.50 4 documents retreived\n",
    "#0.80 No documents retreived\n",
    "#0.75 No documents retreived\n",
    "#0.70 3 documents retreived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dc3aa366",
   "metadata": {},
   "outputs": [],
   "source": [
    "query=\"What is text embedding and how does langchain help in doing it\"\n",
    "docs = retreivers.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "87d396a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='97faa254-46a5-40c8-94b3-384f4a6a7843', metadata={'source': '..\\\\RAGFiles\\\\LangchainRetrieval.txt'}, page_content='Text embedding models\\nAnother key part of retrieval is creating embeddings for documents. Embeddings capture the semantic meaning of the text, allowing you to quickly and efficiently find other pieces of a text that are similar. LangChain provides integrations with over 25 different embedding providers and methods, from open-source to proprietary API, allowing you to choose the one best suited for your needs. LangChain provides a standard interface, allowing you to easily swap between models.'),\n",
       " Document(id='5e6c177d-5f80-42f3-8884-ea19882391be', metadata={'source': '..\\\\RAGFiles\\\\LangchainRetrieval.txt'}, page_content='Text embedding models\\nAnother key part of retrieval is creating embeddings for documents. Embeddings capture the semantic meaning of the text, allowing you to quickly and efficiently find other pieces of a text that are similar. LangChain provides integrations with over 25 different embedding providers and methods, from open-source to proprietary API, allowing you to choose the one best suited for your needs. LangChain provides a standard interface, allowing you to easily swap between models.'),\n",
       " Document(id='7369ab79-d8b4-49c9-8470-532b0bc20f01', metadata={'source': '..\\\\RAGFiles\\\\LangchainRetrieval.txt'}, page_content='Text embedding models\\nAnother key part of retrieval is creating embeddings for documents. Embeddings capture the semantic meaning of the text, allowing you to quickly and efficiently find other pieces of a text that are similar. LangChain provides integrations with over 25 different embedding providers and methods, from open-source to proprietary API, allowing you to choose the one best suited for your needs. LangChain provides a standard interface, allowing you to easily swap between models.\\n\\nVector stores\\nWith the rise of embeddings, there has emerged a need for databases to support efficient storage and searching of these embeddings. LangChain provides integrations with over 50 different vectorstores, from open-source local ones to cloud-hosted proprietary ones, allowing you to choose the one best suited for your needs. LangChain exposes a standard interface, allowing you to easily swap between vector stores.')]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1312419",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
